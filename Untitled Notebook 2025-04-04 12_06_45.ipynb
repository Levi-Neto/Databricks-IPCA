{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f804c073-ac72-4a87-b9ad-f3960634a32e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados e convertidos com sucesso! âœ…\nDados armazenados no Delta Lake com sucesso! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# importando bibliotecas necessÃ¡rias\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, DateType, FloatType\n",
    "\n",
    "# criando a sessÃ£o do Spark (necessÃ¡rio no Databricks)\n",
    "spark = SparkSession.builder.appName(\"IPCA_Delta\").getOrCreate()\n",
    "\n",
    "# url da api do Bacen para ipca de 2004 a 24\n",
    "url = \"https://api.bcb.gov.br/dados/serie/bcdata.sgs.433/dados?formato=json&dataInicial=01/01/2004&dataFinal=31/12/2024\"\n",
    "\n",
    "# fazendo a requisiÃ§Ã£o dos dados\n",
    "resposta = requests.get(url)\n",
    "\n",
    "# verificando se a requisiÃ§Ã£o foi bem-sucedida\n",
    "if resposta.status_code == 200:\n",
    "    # convertendo para JSON\n",
    "    dados = resposta.json()\n",
    "    \n",
    "    # criando um dataframe pandas\n",
    "    df = pd.DataFrame(dados)\n",
    "    \n",
    "    # convertendo a coluna \"data\" para formato datetime\n",
    "    df[\"data\"] = pd.to_datetime(df[\"data\"], format=\"%d/%m/%Y\")\n",
    "    \n",
    "    # convertendo a coluna \"valor\" para float\n",
    "    df[\"valor\"] = df[\"valor\"].astype(float)\n",
    "    \n",
    "    # renomeando colunas para melhor identificaÃ§Ã£o\n",
    "    df.rename(columns={\"data\": \"Data\", \"valor\": \"IPCA\"}, inplace=True)\n",
    "    \n",
    "    print(\"Dados carregados e convertidos com sucesso! âœ…\")\n",
    "else:\n",
    "    print(\"Erro ao buscar os dados:\", resposta.status_code)\n",
    "\n",
    "# defindo o schema do dataframe spark\n",
    "schema = StructType([\n",
    "    StructField(\"Data\", DateType(), True),  #  Data\n",
    "    StructField(\"IPCA\", FloatType(), True)  #  Float\n",
    "])\n",
    "\n",
    "# convertendo o dataframe pandas para dataframe spark\n",
    "df_spark = spark.createDataFrame(df, schema=schema)\n",
    "\n",
    "# caminho para armazenar os dados no delta lake\n",
    "delta_path = \"/mnt/datalake/ipca_delta\"\n",
    "\n",
    "# salvando os dados no formato delta\n",
    "df_spark.write.format(\"delta\").mode(\"overwrite\").save(delta_path)\n",
    "\n",
    "# criando a tabela delta\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS ipca_table USING DELTA LOCATION '{delta_path}'\")\n",
    "\n",
    "print(\"Dados armazenados no Delta Lake com sucesso! ðŸš€\")\n",
    "\n",
    "df_spark.write.csv(\"/dbfs/FileStore/tables/ipca_data.csv\", header=True, mode=\"overwrite\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-04-04 12:06:45",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}